{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchio as tio\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from modules.Dataset import FeTADataSet\n",
    "from modules.Evaluator import Evaluator2D\n",
    "from modules.LossFunctions import DC_and_CE_loss, GDiceLossV2\n",
    "from modules.UNet import UNet2Dv2\n",
    "from modules.Utils import calculate_dice_score, create_onehot_mask, init_weights_kaiming\n",
    "from modules.Utils import TensorboardModules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyper-parameters \n",
    "num_epochs = 250\n",
    "batch_size_ = 1\n",
    "lr_ = 0.01\n",
    "momentum_ = 0.9\n",
    "nesterov_ = True\n",
    "shape = (256, 256, 256)\n",
    "\n",
    "output_path = \"output/UNet2D/run1\"\n",
    "weight_path = os.path.join(output_path, \"weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output and path if it is not exist.\n",
    "if not os.path.isdir(weight_path):\n",
    "    os.makedirs(weight_path)\n",
    "\n",
    "tb = TensorboardModules(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"feta_2.1/dseg.tsv\", sep='\\t', index_col=\"index\")\n",
    "\n",
    "transform_ = transforms.Compose([tio.ZNormalization(masking_method=tio.ZNormalization.mean)])\n",
    "\n",
    "train = FeTADataSet(\"train\", path=\"data\", transform=transform_)\n",
    "val = FeTADataSet(\"val\", path=\"data\", transform=transform_)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size_)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val, batch_size=batch_size_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([126, 256, 256])\n",
      "torch.Size([126, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Add some images and corresponding masks into Tensorboard.\n",
    "mri_image, mri_mask = val[8]\n",
    "slices = (80, 150, 10)\n",
    "tb.add_images(\"Fetal Brain Images\", mri_image, slices)\n",
    "tb.add_images(\"Fetal Brain Masks\", mri_mask, slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet2Dv2().to(device)\n",
    "model.apply(init_weights_kaiming)\n",
    "\n",
    "# Add model graph to Tensorboard.\n",
    "tb.add_graph(model, (256, 256), device)\n",
    "#print(summary(model, input_size=(1, 256, 256)))\n",
    "\n",
    "criterion = DC_and_CE_loss({'batch_dice': True, 'smooth': 1e-5, 'do_bg': False, 'square': False}, {})\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_, momentum=momentum_, nesterov=nesterov_)\n",
    "\n",
    "# Initalize evaluator for validation.\n",
    "evaluator = Evaluator2D(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6758439540863037\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Sum losses and dice scores for all predicitions.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_forward = 0\n",
    "n_total_steps = len(train_loader)\n",
    "running_loss = 0.0\n",
    "running_dice_scores = torch.zeros(8).to(device)\n",
    "bs_2d = 16\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (image, mask) in enumerate(train_loader):\n",
    "        image = image.to(device) #[bs,x,y,z]        \n",
    "        mask = mask.to(device) #[x,y,z]\n",
    "        \n",
    "        # Slice 3D image. It's like splitting 3D images into batches.\n",
    "        for slice_ix in range(0, image.shape[-1], bs_2d):\n",
    "            start = slice_ix\n",
    "            stop = slice_ix+bs_2d\n",
    "            \n",
    "            if stop > image.shape[-1]:\n",
    "                stop = image.shape[-1]-1\n",
    "            \n",
    "            slice_image = image[:, start:stop]\n",
    "            slice_mask = mask[:, start:stop]\n",
    "            slice_image = slice_image.view(-1, 1, 256, 256)\n",
    "            slice_mask = slice_mask.view(-1, 1, 256, 256)\n",
    "                           \n",
    "            outputs = model(slice_image.float())            \n",
    "            one_hot_mask = create_onehot_mask(outputs.shape, slice_mask)\n",
    "            \n",
    "            loss = criterion(outputs, slice_mask)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Sum losses and dice scores for all predicitions.\n",
    "            running_loss += loss.item()\n",
    "            count_forward += 1\n",
    "        \n",
    "        \n",
    "    # Save torch model.                \n",
    "    model_name = \"_\".join([str(epoch+1), str(lr_), str(nesterov_), \"model.pth\"])\n",
    "    torch.save(model.state_dict(), os.path.join(weight_path, model_name))    \n",
    "    \n",
    "    # Add average loss per 10th step to Tensorboard.\n",
    "    avg_loss = running_loss / count_forward\n",
    "    step = epoch * n_total_steps + i\n",
    "    tb.add_loss(avg_loss, step)\n",
    "    #Set values to zero for new calculations.\n",
    "    count_forward = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss}\")\n",
    "    \n",
    "    #Add average dice score per 10th step to Tensorboard.\n",
    "    avg_scores = evaluator.evaluate(model)\n",
    "    tb.add_dice_score(avg_scores, epoch)\n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"weights/UNet2D/139_0.01_True_model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results.\n",
    "im_id = 4\n",
    "slice_id = 72\n",
    "class_index = 0\n",
    "\n",
    "image, mask = test[im_id]\n",
    "image = torch.Tensor(image)\n",
    "\n",
    "inp = image[:, :, slice_id].view(1, 1, 256, 256)\n",
    "inp = torch.Tensor(inp).to(device)\n",
    "out = F.softmax(model(inp.float()), dim=1)\n",
    "\n",
    "gt = torch.Tensor(mask[:, :, slice_id]).view(1, 1, 256, 256)\n",
    "gt = create_onehot_mask(out.shape, gt.to(device), device)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "ax[0].imshow(image[:, :, slice_id])\n",
    "ax[1].imshow(out[0, class_index].cpu().detach().numpy(), cmap=\"gray\")\n",
    "ax[2].imshow(gt[0, class_index].cpu(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
