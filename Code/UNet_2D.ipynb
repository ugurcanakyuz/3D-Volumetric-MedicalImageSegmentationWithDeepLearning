{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchio as tio\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from modules.Dataset import FeTADataSet\n",
    "from modules.Evaluator import Evaluator2D\n",
    "from modules.LossFunctions import DC_and_CE_loss, GDiceLossV2\n",
    "from modules.Trainer import Trainer2D\n",
    "from modules.UNet import UNet2D\n",
    "from modules.Utils import calculate_dice_score, create_onehot_mask, init_weights_kaiming\n",
    "from modules.Utils import EarlyStopping, TensorboardModules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyper-parameters \n",
    "params = {\"num_epochs\": 250,\n",
    "          \"batch_size\": 1,\n",
    "          \"lr\": 0.1,\n",
    "          \"momentum\": 0.9,\n",
    "          \"nesterov\": True,\n",
    "         }\n",
    "\n",
    "output_path = \"output/UNet2D/run2\"\n",
    "weight_path = os.path.join(output_path, \"weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output and path if it is not exist.\n",
    "if not os.path.isdir(weight_path):\n",
    "    os.makedirs(weight_path)\n",
    "    \n",
    "tb = TensorboardModules(output_path)\n",
    "# Save hyperparameters as note.\n",
    "(pd.DataFrame.from_dict(data=params, orient='index')\n",
    " .to_csv(os.path.join(output_path,\"hyper_parameters.txt\"), header=False, sep=\"=\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"feta_2.1/dseg.tsv\", sep='\\t', index_col=\"index\")\n",
    "\n",
    "transform_ = transforms.Compose([tio.ZNormalization(masking_method=tio.ZNormalization.mean)])\n",
    "\n",
    "train = FeTADataSet(\"train\", path=\"data\", transform=transform_)\n",
    "val = FeTADataSet(\"val\", path=\"data\", transform=transform_)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=params[\"batch_size\"])\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val, batch_size=params[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some images and corresponding masks into Tensorboard.\n",
    "mri_image, mri_mask = val[8]\n",
    "slices = (80, 150, 10)\n",
    "tb.add_images(\"Fetal Brain Images\", mri_image, slices)\n",
    "tb.add_images(\"Fetal Brain Masks\", mri_mask, slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet2D().to(device)\n",
    "model.apply(init_weights_kaiming)\n",
    "\n",
    "# Add model graph to Tensorboard.\n",
    "tb.add_graph(model, (256, 256), device)\n",
    "#print(summary(model, input_size=(1, 256, 256)))\n",
    "\n",
    "criterion = DC_and_CE_loss({'batch_dice': True, 'smooth': 1e-5, 'do_bg': False, 'square': False}, {})\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params[\"lr\"], \n",
    "                            momentum=params[\"momentum\"], nesterov=params[\"nesterov\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "# Initalize trainer for training.\n",
    "trainer = Trainer2D(model, train_loader, optimizer, criterion, params[\"num_epochs\"], scheduler)\n",
    "\n",
    "# Initalize evaluator for validation.\n",
    "evaluator = Evaluator2D(criterion, model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prev_weights = \"\"\n",
    "prev_val_loss = 100\n",
    "\n",
    "for epoch in range(params[\"num_epochs\"]):\n",
    "    # One forward pass for all training data.\n",
    "    avg_train_loss = trainer.fit()\n",
    "    \n",
    "    # Evaluate current model on validation data.\n",
    "    avg_val_loss, avg_scores = evaluator.evaluate(model)\n",
    "    \n",
    "    # Add results to tensorboard.\n",
    "    tb.add_scalars(step=epoch, lr=scheduler.get_last_lr()[0], ds=avg_scores, \n",
    "                   train_loss=avg_train_loss, val_loss=avg_val_loss)\n",
    "    \n",
    "    model_name = \"_\".join([str(epoch), \"model.pth\"])\n",
    "    model_path = os.path.join(weight_path, model_name)\n",
    "    \n",
    "    if avg_val_loss < prev_val_loss:\n",
    "        # Save trained weights.\n",
    "        if os.path.isfile(prev_weights):\n",
    "            os.remove(prev_weights)        \n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "    prev_weights = model_path        \n",
    "    prev_val_loss = avg_val_loss\n",
    "    \n",
    "    # If model is not learning stop the training.\n",
    "    early_stopping(avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"weights/UNet2D/139_0.01_True_model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results.\n",
    "im_id = 4\n",
    "slice_id = 72\n",
    "class_index = 0\n",
    "\n",
    "image, mask = test[im_id]\n",
    "image = torch.Tensor(image)\n",
    "\n",
    "inp = image[:, :, slice_id].view(1, 1, 256, 256)\n",
    "inp = torch.Tensor(inp).to(device)\n",
    "out = F.softmax(model(inp.float()), dim=1)\n",
    "\n",
    "gt = torch.Tensor(mask[:, :, slice_id]).view(1, 1, 256, 256)\n",
    "gt = create_onehot_mask(out.shape, gt.to(device), device)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "ax[0].imshow(image[:, :, slice_id])\n",
    "ax[1].imshow(out[0, class_index].cpu().detach().numpy(), cmap=\"gray\")\n",
    "ax[2].imshow(gt[0, class_index].cpu(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4py3",
   "language": "python",
   "name": "cv4py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
