{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import default libraries\n",
    "import os\n",
    "from datetime import datetime\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 3rd party libraries\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "import torchio as tio\n",
    "from torchsummary import summary\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tAb77yZ9fzMG"
   },
   "outputs": [],
   "source": [
    "# Import user defined libraries\n",
    "from data.Dataset import FeTABalancedDistribution, MRIDataset\n",
    "from data.transforms import *\n",
    "from models import Evaluator3D, SDUNet3D, Trainer3D\n",
    "from utils.Config import Config\n",
    "from utils.LossFunctions import DC_and_CE_loss\n",
    "from utils.Utils import *\n",
    "from visualization.Tensorboard import TensorboardModules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tAp5iDVkXVo5"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(0)\n",
    "\n",
    "cfg = Config('config.yaml')\n",
    "cfg_dict = cfg.as_dict()\n",
    "\n",
    "output_path = '../models/{}/Test/'.format(datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
    "weight_path = os.path.join(output_path, \"weights/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5VWdtdClXW53",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset operations\n",
    "\n",
    "# There are multiple data folders belong to same dataset. Each of them processed in different ways.\n",
    "# Therefore, path of the data and its name explicitly are defined.\n",
    "dataset_train = FeTABalancedDistribution\n",
    "dataset_val = FeTABalancedDistribution\n",
    "\n",
    "#cv_ = \"cv3\" # 5-fold cross-validation. Folds [cv1-cv5]\n",
    "\n",
    "# Transformations.\n",
    "transform_train = transforms.Compose([tio.transforms.RandomAffine(scales=(0.95, 1.05)),\n",
    "                                      tio.transforms.RandomMotion(), \n",
    "                                      tio.transforms.RandomNoise()])\n",
    "\n",
    "transform_eval = None # transforms.Compose([Mask()])\n",
    "\n",
    "\n",
    "train = MRIDataset(dataset_train, \"train\", cfg.data.train_path, transform=transform_train)\n",
    "train_queue = tio.Queue(subjects_dataset=train.dataset, max_length=216, samples_per_volume=8,\n",
    "                        sampler=tio.UniformSampler(patch_size=cfg.data.patch_size), num_workers=4)\n",
    "\n",
    "val = MRIDataset(dataset_val, \"val\", cfg.data.val_path, transform=transform_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader operations\n",
    "train_loader = DataLoader(dataset=train_queue, batch_size=cfg.data.batch_size, num_workers=0, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val, batch_size=cfg.data.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dataset configuration to parameters to save them as meta data.\n",
    "cfg_dict[\"data\"][\"dataset_train\"] = str(dataset_train).split(\"'\")[1].split('.')[-1]\n",
    "cfg_dict[\"data\"][\"dataset_val\"] = str(dataset_train).split(\"'\")[1].split('.')[-1]\n",
    "#cfg_dict[\"data\"][\"cross_validation\"] = \"None\" if not cv_ else cv_\n",
    "cfg_dict[\"data\"][\"transform_train\"] = \"None\" if not transform_train else str(transform_train.transforms)\n",
    "cfg_dict[\"data\"][\"transform_eval\"] = \"None\" if not transform_eval else str(transform_eval.transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SDUNet3D().to(device)\n",
    "criterion = DC_and_CE_loss({'batch_dice': True, 'smooth': 1e-5, 'do_bg': False, 'square': False}, {})\n",
    "pretrained = False\n",
    "\n",
    "# Initalize weights or load already trained model.\n",
    "if not pretrained:\n",
    "    cfg_dict[\"initial_weights\"] = 'Random' \n",
    "else:\n",
    "    model_path = \"../models/20230107/SDUNet/weights/34_model.pth\"\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    cfg_dict[\"initial_weights\"] = model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cHHDkEKkXYg_",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=cfg.optimizer.SGD.lr, \n",
    "                            momentum=cfg.optimizer.SGD.momentum, nesterov=cfg.optimizer.SGD.nesterov)\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=cfg.lr_scheduler.CLR.base, \n",
    "                                              max_lr=cfg.lr_scheduler.CLR.max,\n",
    "                                              step_size_up=cfg.lr_scheduler.CLR.up, \n",
    "                                              step_size_down=cfg.lr_scheduler.CLR.down,\n",
    "                                              mode=cfg.lr_scheduler.CLR.mode)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=cfg.lr_scheduler.SLR.step_size], \n",
    "                                            #gamma=cfg.lr_scheduler.SLR.gamma)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=cfg.training.ES.patience, min_delta=cfg.training.ES.min_delta)\n",
    "\n",
    "\n",
    "# Initalize trainer for training.\n",
    "trainer = Trainer3D(criterion, model, optimizer, cfg.training.total_epoch, train_loader, scheduler)\n",
    "\n",
    "# Initalize evaluator for validation.\n",
    "evaluator = Evaluator3D(criterion, model, cfg.data.patch_size, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output and path if it is not exist.\n",
    "if not os.path.isdir(weight_path):\n",
    "    os.makedirs(weight_path)\n",
    "\n",
    "# Create Tensorboard object to save experiment outputs.    \n",
    "tb = TensorboardModules(output_path)\n",
    "\n",
    "# Save paramaters.\n",
    "with open(os.path.join(output_path, 'config.yaml'), 'w') as outfile:\n",
    "    yaml.dump(cfg_dict, outfile, default_flow_style=False)\n",
    "\n",
    "# Add some images and corresponding masks into Tensorboard.\n",
    "mri_image, mri_mask = val[0]['mri']['data'].squeeze(0), val[0]['mask']['data'].squeeze(0)\n",
    "slices = (50, 100, 10)\n",
    "tb.add_image_mask(mri_image, mri_mask, slices)\n",
    "\n",
    "# Add model graph to Tensorboard.\n",
    "tb.add_graph(model, cfg.data.patch_size, device)\n",
    "# print(summary(model, input_size=(1, 32, 128, 128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "r2tSNZTXXaCA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]: 100%|██████████| 464/464 [07:04<00:00,  1.09it/s, Loss: 1.0879]\n",
      "Validation : 100%|██████████| 10/10 [00:36<00:00,  3.66s/it, Loss: 0.5776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/50]: 100%|██████████| 464/464 [07:04<00:00,  1.09it/s, Loss: -0.0427]\n",
      "Validation : 100%|██████████| 10/10 [00:37<00:00,  3.70s/it, Loss: -0.4070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/50]: 100%|██████████| 464/464 [07:04<00:00,  1.09it/s, Loss: -0.4919]\n",
      "Validation : 100%|██████████| 10/10 [00:36<00:00,  3.67s/it, Loss: -0.6547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/50]:  10%|█         | 48/464 [00:42<06:12,  1.12it/s, Loss: -0.4507]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m prev_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, cfg\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mtotal_epoch):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# One forward pass for all training data.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Evaluate current model on validation data.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     avg_val_loss, dice_scores \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m/home/dev/3D-Volumetric-MedicalImageSegmentationWithDeepLearning/src/models/Trainer.py:73\u001b[0m, in \u001b[0;36mTrainer3D.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, patch_mask)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 73\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     75\u001b[0m running_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prev_weights = \"\"\n",
    "prev_val_loss = 100\n",
    "\n",
    "for epoch in range(0, cfg.training.total_epoch):\n",
    "    # One forward pass for all training data.\n",
    "    avg_train_loss = trainer.fit()\n",
    "    \n",
    "    # Evaluate current model on validation data.\n",
    "    avg_val_loss, dice_scores = evaluator.evaluate()\n",
    "    avg_scores = sum(dice_scores) / len(dice_scores)\n",
    "    \n",
    "    print(\"-------------------------------------------------------------\")\n",
    "    \n",
    "    # Add results to tensorboard.\n",
    "    tb.add_scalars(step=epoch+1, lr=scheduler.get_last_lr()[0], ds=avg_scores, \n",
    "                   train_loss=avg_train_loss, val_loss=avg_val_loss)\n",
    "    \n",
    "    model_name = \"_\".join([str(epoch), \"model.pth\"])\n",
    "    model_path = os.path.join(weight_path, model_name)\n",
    "    \n",
    "    if avg_val_loss < prev_val_loss:\n",
    "        # Save trained weights.\n",
    "        if os.path.isfile(prev_weights):\n",
    "            os.remove(prev_weights)        \n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "    prev_weights = model_path        \n",
    "    prev_val_loss = avg_val_loss\n",
    "    \n",
    "    # If model is not learning stop the training.\n",
    "    early_stopping(avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "UNet_3D.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
